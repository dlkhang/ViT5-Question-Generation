{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UB0Fnifrdfla"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjhVSB+gSydv5sOGBhtP7h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlkhang/ViT5-Question-Generation/blob/main/final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJu77LTNQCKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b72af0-2de7-4986-aa4e-4bd5a7c1b6b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Train 5 epoch"
      ],
      "metadata": {
        "id": "eGEEG5mgQO-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "vit5"
      ],
      "metadata": {
        "id": "baGh6hvRRH_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets sentencepiece accelerate\n",
        "\n",
        "import os, shutil, gc, torch\n",
        "from google.colab import drive\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
        "\n",
        "# 1. Cáº¥u hÃ¬nh\n",
        "if not os.path.exists('/content/drive'): drive.mount('/content/drive')\n",
        "DATA_DIR = \"/content/drive/MyDrive/KhoaLuan/data\"\n",
        "TRAIN_FILE = os.path.join(DATA_DIR, \"train_grouped_CLEAN_OPTIMIZED.json\")\n",
        "VAL_FILE   = os.path.join(DATA_DIR, \"val_grouped_CLEAN_OPTIMIZED.json\")\n",
        "FINAL_DIR  = \"/content/drive/MyDrive/KhoaLuan/model_vit5_final_5ep\"\n",
        "TEMP_DIR   = \"/content/vit5_temp\"\n",
        "\n",
        "# 2. Chuáº©n bá»‹ Data\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vietai/vit5-base\")\n",
        "def preprocess(examples):\n",
        "    inputs = tokenizer(examples[\"input_text\"], max_length=320, padding=\"max_length\", truncation=True)\n",
        "    targets = tokenizer(text_target=examples[\"output_text\"], max_length=256, padding=\"max_length\", truncation=True)\n",
        "    targets[\"input_ids\"] = [[(l if l != tokenizer.pad_token_id else -100) for l in label] for label in targets[\"input_ids\"]]\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files={\"train\": TRAIN_FILE, \"validation\": VAL_FILE})\n",
        "tokenized = dataset.map(preprocess, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
        "\n",
        "# 3. Train\n",
        "gc.collect(); torch.cuda.empty_cache()\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"vietai/vit5-base\")\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=TEMP_DIR,\n",
        "    learning_rate=3e-4,\n",
        "    num_train_epochs=5,\n",
        "    lr_scheduler_type=\"cosine\", warmup_ratio=0.05, label_smoothing_factor=0.1, weight_decay=0.02,\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=1,\n",
        "    fp16=True,\n",
        "    save_strategy=\"no\",\n",
        "    logging_steps=100, report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(model=model, args=args, train_dataset=tokenized[\"train\"], eval_dataset=tokenized[\"validation\"], tokenizer=tokenizer, data_collator=DataCollatorForSeq2Seq(tokenizer, model=model))\n",
        "\n",
        "print(\"\\nğŸ”¥ TRAIN ViT5...\")\n",
        "trainer.train()\n",
        "\n",
        "# 4. LÆ°u Model\n",
        "print(f\"\\nğŸ“¦ Äang lÆ°u vá»: {FINAL_DIR}\")\n",
        "if os.path.exists(FINAL_DIR): shutil.rmtree(FINAL_DIR)\n",
        "trainer.save_model(FINAL_DIR)\n",
        "tokenizer.save_pretrained(FINAL_DIR)\n",
        "print(\"âœ… ÄÃ£ lÆ°u ViT5!\")"
      ],
      "metadata": {
        "id": "eHW1BR92QR2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bart-pho"
      ],
      "metadata": {
        "id": "YTCfsIRFRKKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets sentencepiece accelerate\n",
        "\n",
        "import os, shutil, gc, torch\n",
        "from google.colab import drive\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
        "\n",
        "# 1. Cáº¥u hÃ¬nh\n",
        "if not os.path.exists('/content/drive'): drive.mount('/content/drive')\n",
        "DATA_DIR = \"/content/drive/MyDrive/KhoaLuan/data\"\n",
        "TRAIN_FILE = os.path.join(DATA_DIR, \"train_grouped_CLEAN_OPTIMIZED.json\")\n",
        "VAL_FILE   = os.path.join(DATA_DIR, \"val_grouped_CLEAN_OPTIMIZED.json\")\n",
        "FINAL_DIR  = \"/content/drive/MyDrive/KhoaLuan/model_bartpho_final_5ep\"\n",
        "TEMP_DIR   = \"/content/bartpho_temp\"\n",
        "\n",
        "# 2. Chuáº©n bá»‹ Data\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-syllable\")\n",
        "def preprocess(examples):\n",
        "    inputs = tokenizer(examples[\"input_text\"], max_length=320, padding=\"max_length\", truncation=True)\n",
        "    targets = tokenizer(text_target=examples[\"output_text\"], max_length=256, padding=\"max_length\", truncation=True)\n",
        "    targets[\"input_ids\"] = [[(l if l != tokenizer.pad_token_id else -100) for l in label] for label in targets[\"input_ids\"]]\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files={\"train\": TRAIN_FILE, \"validation\": VAL_FILE})\n",
        "tokenized = dataset.map(preprocess, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
        "\n",
        "# 3. Train\n",
        "gc.collect(); torch.cuda.empty_cache()\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"vinai/bartpho-syllable\")\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=TEMP_DIR,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=5,\n",
        "    lr_scheduler_type=\"cosine\", warmup_ratio=0.05, label_smoothing_factor=0.1, weight_decay=0.02,\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=2,\n",
        "    fp16=True,\n",
        "    save_strategy=\"no\",\n",
        "    logging_steps=100, report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(model=model, args=args, train_dataset=tokenized[\"train\"], eval_dataset=tokenized[\"validation\"], tokenizer=tokenizer, data_collator=DataCollatorForSeq2Seq(tokenizer, model=model))\n",
        "\n",
        "print(\"\\nğŸ”¥ TRAIN BARTpho...\")\n",
        "trainer.train()\n",
        "\n",
        "# 4. LÆ°u Model\n",
        "print(f\"\\nğŸ“¦ Äang lÆ°u vá»: {FINAL_DIR}\")\n",
        "if os.path.exists(FINAL_DIR): shutil.rmtree(FINAL_DIR)\n",
        "trainer.save_model(FINAL_DIR)\n",
        "tokenizer.save_pretrained(FINAL_DIR)\n",
        "print(\"âœ… ÄÃ£ lÆ°u BARTpho!\")"
      ],
      "metadata": {
        "id": "yInh9NuRRDHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "t5"
      ],
      "metadata": {
        "id": "BmDx7dRoRMht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets sentencepiece accelerate\n",
        "\n",
        "import os, shutil, gc, torch\n",
        "from google.colab import drive\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
        "\n",
        "# 1. Cáº¥u hÃ¬nh\n",
        "if not os.path.exists('/content/drive'): drive.mount('/content/drive')\n",
        "DATA_DIR = \"/content/drive/MyDrive/KhoaLuan/data\"\n",
        "TRAIN_FILE = os.path.join(DATA_DIR, \"train_grouped_CLEAN_OPTIMIZED.json\")\n",
        "VAL_FILE   = os.path.join(DATA_DIR, \"val_grouped_CLEAN_OPTIMIZED.json\")\n",
        "FINAL_DIR  = \"/content/drive/MyDrive/KhoaLuan/model_t5_base_final_5ep\"\n",
        "TEMP_DIR   = \"/content/t5_base_temp\"\n",
        "\n",
        "# 2. Chuáº©n bá»‹ Data\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
        "def preprocess(examples):\n",
        "    inputs = tokenizer(examples[\"input_text\"], max_length=320, padding=\"max_length\", truncation=True)\n",
        "    targets = tokenizer(text_target=examples[\"output_text\"], max_length=256, padding=\"max_length\", truncation=True)\n",
        "    targets[\"input_ids\"] = [[(l if l != tokenizer.pad_token_id else -100) for l in label] for label in targets[\"input_ids\"]]\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files={\"train\": TRAIN_FILE, \"validation\": VAL_FILE})\n",
        "tokenized = dataset.map(preprocess, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
        "\n",
        "# 3. Train\n",
        "gc.collect(); torch.cuda.empty_cache()\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=TEMP_DIR,\n",
        "    learning_rate=3e-4,\n",
        "    num_train_epochs=5,\n",
        "    lr_scheduler_type=\"cosine\", warmup_ratio=0.05, label_smoothing_factor=0.1, weight_decay=0.02,\n",
        "\n",
        "    # Cáº¥u hÃ¬nh chá»‘ng lá»—i NaN\n",
        "    fp16=False,\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=2,\n",
        "    gradient_checkpointing=True,\n",
        "\n",
        "    save_strategy=\"no\",\n",
        "    logging_steps=100, report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(model=model, args=args, train_dataset=tokenized[\"train\"], eval_dataset=tokenized[\"validation\"], tokenizer=tokenizer, data_collator=DataCollatorForSeq2Seq(tokenizer, model=model))\n",
        "\n",
        "print(\"\\nğŸ”¥ TRAIN t5-base...\")\n",
        "trainer.train()\n",
        "\n",
        "# 4. LÆ°u Model\n",
        "print(f\"\\nğŸ“¦ Äang lÆ°u vá»: {FINAL_DIR}\")\n",
        "if os.path.exists(FINAL_DIR): shutil.rmtree(FINAL_DIR)\n",
        "trainer.save_model(FINAL_DIR)\n",
        "tokenizer.save_pretrained(FINAL_DIR)\n",
        "print(\"âœ… ÄÃ£ lÆ°u t5-base!\")"
      ],
      "metadata": {
        "id": "cWq-gxekRHKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. So sÃ¡nh 3 mÃ´ hÃ¬nh"
      ],
      "metadata": {
        "id": "UB0Fnifrdfla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# ğŸ“Š CODE ÄÃNH GIÃ & SO SÃNH 3 MÃ” HÃŒNH (5 EPOCHS)\n",
        "# ==============================================================================\n",
        "\n",
        "# 1. CÃ€I Äáº¶T THÆ¯ VIá»†N CHáº¤M ÄIá»‚M\n",
        "print(\"â³ Äang cÃ i Ä‘áº·t thÆ° viá»‡n evaluate, rouge_score...\")\n",
        "!pip install -q evaluate rouge_score absl-py nltk matplotlib pandas\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "print(\"âœ… CÃ i Ä‘áº·t xong!\")\n",
        "\n",
        "import torch\n",
        "import json\n",
        "import gc\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "# 2. Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN (ÄÃšNG THEO CÃC MODEL 5 EP Báº N Vá»ªA TRAIN)\n",
        "# ------------------------------------------------------------------------------\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# File Test (Validation)\n",
        "TEST_DATA_PATH = \"/content/drive/MyDrive/KhoaLuan/data/test_grouped_CLEAN_OPTIMIZED.json\"\n",
        "\n",
        "# Danh sÃ¡ch Model cáº§n so sÃ¡nh\n",
        "MODELS_TO_EVAL = [\n",
        "    {\n",
        "        \"name\": \"ViT5\",\n",
        "        \"path\": \"/content/drive/MyDrive/KhoaLuan/model_final/5ep/model_vit5_final_5ep\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"BARTpho\",\n",
        "        \"path\": \"/content/drive/MyDrive/KhoaLuan/model_final/5ep/model_bartpho_final_5ep\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"T5-base\",\n",
        "        \"path\": \"/content/drive/MyDrive/KhoaLuan/model_final/5ep/model_t5_base_final_5ep\"\n",
        "    }\n",
        "]\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# 3. HÃ€M TÃNH ÄIá»‚M\n",
        "# ------------------------------------------------------------------------------\n",
        "metric_bleu = evaluate.load(\"bleu\")\n",
        "metric_meteor = evaluate.load(\"meteor\")\n",
        "metric_rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def calculate_metrics(predictions, references):\n",
        "    # BLEU\n",
        "    results_bleu = metric_bleu.compute(predictions=predictions, references=references)\n",
        "    # METEOR\n",
        "    results_meteor = metric_meteor.compute(predictions=predictions, references=references)\n",
        "    # ROUGE\n",
        "    results_rouge = metric_rouge.compute(predictions=predictions, references=references)\n",
        "\n",
        "    return {\n",
        "        \"BLEU\": round(results_bleu['bleu'] * 100, 2),\n",
        "        \"METEOR\": round(results_meteor['meteor'] * 100, 2),\n",
        "        \"ROUGE-L\": round(results_rouge['rougeL'] * 100, 2),\n",
        "    }\n",
        "\n",
        "# 4. HÃ€M SINH CÃ‚U Há»I (QUáº¢N LÃ RAM CHáº¶T CHáº¼)\n",
        "# ------------------------------------------------------------------------------\n",
        "def evaluate_model(model_info, test_data):\n",
        "    model_name = model_info['name']\n",
        "    model_path = model_info['path']\n",
        "\n",
        "    print(f\"\\n\" + \"=\"*50)\n",
        "    print(f\"ğŸ”„ Äang khá»Ÿi Ä‘á»™ng: {model_name}...\")\n",
        "    print(f\"ğŸ“‚ Load tá»«: {model_path}\")\n",
        "\n",
        "    # Kiá»ƒm tra Ä‘Æ°á»ng dáº«n\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"âŒ KhÃ´ng tÃ¬m tháº¥y folder model táº¡i {model_path}. Bá» qua...\")\n",
        "        return None, None\n",
        "\n",
        "    # Load Model & Tokenizer\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(DEVICE)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Lá»—i load model: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    predictions = []\n",
        "    print(f\"ğŸš€ Äang sinh cÃ¢u há»i (Beam Search=5)...\")\n",
        "\n",
        "    # Cháº¡y loop tá»«ng máº«u (an toÃ n nháº¥t cho RAM)\n",
        "    for item in tqdm(test_data):\n",
        "        input_text = item['input_text'] # Láº¥y Ä‘Ãºng trÆ°á»ng input_text trong JSON\n",
        "\n",
        "        inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=320, truncation=True).to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                inputs.input_ids,\n",
        "                max_length=256,\n",
        "                num_beams=5,             # ğŸ”¥ CÃ”NG Báº°NG: Táº¥t cáº£ Ä‘á»u dÃ¹ng Beam 5\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        predictions.append(pred)\n",
        "\n",
        "    # ğŸ§¹ Dá»ŒN Dáº¸P RAM NGAY Láº¬P Tá»¨C\n",
        "    print(f\"ğŸ§¹ Äang giáº£i phÃ³ng RAM sau khi cháº¡y {model_name}...\")\n",
        "    del model\n",
        "    del tokenizer\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# 5. CHáº Y THá»°C NGHIá»†M\n",
        "# ------------------------------------------------------------------------------\n",
        "print(f\"ğŸ“‚ Äang Ä‘á»c dá»¯ liá»‡u Test tá»« {TEST_DATA_PATH}...\")\n",
        "with open(TEST_DATA_PATH, 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# âš ï¸ LÆ¯U Ã: Test trÃªn 200 máº«u Ä‘áº§u tiÃªn cho nhanh.\n",
        "# Muá»‘n test háº¿t 100% thÃ¬ xÃ³a dÃ²ng [:200] Ä‘i (nhÆ°ng sáº½ lÃ¢u Ä‘áº¥y!)\n",
        "test_data = data[:200]\n",
        "print(f\"ğŸ‘‰ Sá»‘ lÆ°á»£ng máº«u Ä‘Ã¡nh giÃ¡: {len(test_data)}\")\n",
        "\n",
        "references = [item['output_text'] for item in test_data]\n",
        "results_list = []\n",
        "example_outputs = {}\n",
        "\n",
        "for model_info in MODELS_TO_EVAL:\n",
        "    preds = evaluate_model(model_info, test_data)\n",
        "\n",
        "    if preds:\n",
        "        scores = calculate_metrics(preds, references)\n",
        "        scores['Model'] = model_info['name']\n",
        "        results_list.append(scores)\n",
        "\n",
        "        # LÆ°u láº¡i 1 vÃ­ dá»¥ Ä‘á»ƒ so sÃ¡nh báº±ng máº¯t\n",
        "        example_outputs[model_info['name']] = preds[0]\n",
        "\n",
        "# 6. HIá»‚N THá»Š Káº¾T QUáº¢ & Váº¼ BIá»‚U Äá»’\n",
        "# ------------------------------------------------------------------------------\n",
        "if results_list:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸ“Š Báº¢NG Tá»”NG Há»¢P Káº¾T QUáº¢ SO SÃNH (5 EPOCHS)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    df = pd.DataFrame(results_list)\n",
        "    # Sáº¯p xáº¿p cá»™t cho Ä‘áº¹p\n",
        "    df = df[['Model', 'BLEU', 'METEOR', 'ROUGE-L']]\n",
        "    print(df.to_markdown(index=False))\n",
        "\n",
        "    # --- Váº¼ BIá»‚U Äá»’ ---\n",
        "    print(\"\\nğŸ¨ Äang váº½ biá»ƒu Ä‘á»“...\")\n",
        "    df.set_index('Model', inplace=True)\n",
        "\n",
        "    # Váº½ biá»ƒu Ä‘á»“ cá»™t nhÃ³m\n",
        "    ax = df.plot(kind='bar', figsize=(10, 6), rot=0, colormap='viridis')\n",
        "\n",
        "    plt.title('So sÃ¡nh hiá»‡u nÄƒng cÃ¡c mÃ´ hÃ¬nh (Sau 5 Epochs)', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Äiá»ƒm sá»‘ (%)')\n",
        "    plt.xlabel('MÃ´ hÃ¬nh')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Hiá»ƒn thá»‹ sá»‘ trÃªn cá»™t\n",
        "    for container in ax.containers:\n",
        "        ax.bar_label(container, fmt='%.1f', padding=3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # --- SO SÃNH THá»°C Táº¾ (QUALITATIVE) ---\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸ“ SO SÃNH CÃ‚U SINH RA (VÃ Dá»¤ MáºªU Äáº¦U TIÃŠN)\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"INPUT: {test_data[0]['input_text']}\")\n",
        "    print(f\"GROUND TRUTH: {test_data[0]['output_text']}\")\n",
        "    print(\"-\" * 30)\n",
        "    for model_name, pred_text in example_outputs.items():\n",
        "        print(f\"ğŸ¤– {model_name}: {pred_text}\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "else:\n",
        "    print(\"âŒ KhÃ´ng cÃ³ káº¿t quáº£ nÃ o Ä‘á»ƒ hiá»ƒn thá»‹. HÃ£y kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n model.\")"
      ],
      "metadata": {
        "id": "KZDGzHzZdh3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Train vit5"
      ],
      "metadata": {
        "id": "UScHn4i3QSut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"â³ Äang cÃ i Ä‘áº·t thÆ° viá»‡n...\")\n",
        "!pip install -q transformers datasets sentencepiece accelerate\n",
        "print(\"âœ… CÃ i Ä‘áº·t hoÃ n táº¥t!\")\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import gc\n",
        "import torch\n",
        "from google.colab import drive\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "\n",
        "# 2. Cáº¤U HÃŒNH Há»† THá»NG & ÄÆ¯á»œNG DáºªN\n",
        "DATA_DIR = \"/content/drive/MyDrive/KhoaLuan/data\"\n",
        "TRAIN_FILE = os.path.join(DATA_DIR, \"train_grouped_CLEAN_OPTIMIZED.json\")\n",
        "VAL_FILE   = os.path.join(DATA_DIR, \"val_grouped_CLEAN_OPTIMIZED.json\")\n",
        "#ten\n",
        "FINAL_DRIVE_DIR = \"/content/drive/MyDrive/KhoaLuan/model_vit5_final_ultra\"\n",
        "TEMP_DIR = \"/content/vit5_temp\"\n",
        "\n",
        "MODEL_CHECKPOINT = \"vietai/vit5-base\"\n",
        "\n",
        "#thÃ´ng sá»‘\n",
        "MAX_INPUT_LENGTH = 320\n",
        "MAX_TARGET_LENGTH = 256\n",
        "\n",
        "#clean\n",
        "if os.path.exists(TEMP_DIR):\n",
        "    shutil.rmtree(TEMP_DIR)\n",
        "os.makedirs(TEMP_DIR, exist_ok=True)\n",
        "\n",
        "print(\"-\" * 60)\n",
        "print(f\"âœ… Data Train: {TRAIN_FILE}\")\n",
        "print(f\"âœ… Model Output: {FINAL_DRIVE_DIR}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# 3. CHUáº¨N Bá»Š Dá»® LIá»†U\n",
        "print(\"\\nğŸ”„ Äang xá»­ lÃ½ dá»¯ liá»‡u...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    model_inputs = tokenizer(\n",
        "        examples[\"input_text\"],\n",
        "        max_length=MAX_INPUT_LENGTH,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    labels = tokenizer(\n",
        "        text_target=examples[\"output_text\"],\n",
        "        max_length=MAX_TARGET_LENGTH,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )\n",
        "    labels[\"input_ids\"] = [\n",
        "        [(l if l != tokenizer.pad_token_id else -100) for l in label]\n",
        "        for label in labels[\"input_ids\"]\n",
        "    ]\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Load vÃ  Map dá»¯ liá»‡u\n",
        "try:\n",
        "    dataset = load_dataset(\"json\", data_files={\"train\": TRAIN_FILE, \"validation\": VAL_FILE})\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Lá»—i load data: {e}\")\n",
        "    raise e\n",
        "\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
        "print(f\"âœ… ÄÃ£ xá»­ lÃ½ xong {len(tokenized_datasets['train'])} máº«u train.\")\n",
        "\n",
        "# 4. Cáº¤U HÃŒNH TRAINING\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=TEMP_DIR,\n",
        "    learning_rate=3e-4,\n",
        "    num_train_epochs=15,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.05,\n",
        "    label_smoothing_factor=0.1,\n",
        "    weight_decay=0.02,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    gradient_accumulation_steps=1,\n",
        "    fp16=True,\n",
        "\n",
        "    # cáº¥u hÃ¬nh lÆ°u\n",
        "    save_total_limit=2,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "\n",
        "    predict_with_generate=False,\n",
        "    logging_steps=100,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
        "   #xet\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=4)]\n",
        ")\n",
        "\n",
        "# 5. Báº®T Äáº¦U TRAIN\n",
        "trainer.train()\n",
        "\n",
        "# XÃ³a rÃ¡c\n",
        "if os.path.exists(FINAL_DRIVE_DIR):\n",
        "    shutil.rmtree(FINAL_DRIVE_DIR)\n",
        "\n",
        "trainer.save_model(FINAL_DRIVE_DIR)\n",
        "tokenizer.save_pretrained(FINAL_DRIVE_DIR)\n",
        "\n",
        "print(\"-\" * 60)\n",
        "print(f\"ğŸ‰ HOÃ€N Táº¤T! Model tá»‘i Æ°u nháº¥t Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i:\")\n",
        "print(f\"ğŸ‘‰ {FINAL_DRIVE_DIR}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "#6. TEST\n",
        "from transformers import pipeline\n",
        "\n",
        "print(\"\\nğŸ¤– Äang test thá»­ 1 máº«u...\")\n",
        "# Load láº¡i model vá»«a lÆ°u Ä‘á»ƒ cháº¯c cháº¯n nÃ³ hoáº¡t Ä‘á»™ng\n",
        "generator = pipeline(\"text2text-generation\", model=FINAL_DRIVE_DIR, tokenizer=FINAL_DRIVE_DIR, device=0)\n",
        "\n",
        "test_context = \"Quang há»£p lÃ  quÃ¡ trÃ¬nh sá»­ dá»¥ng nÄƒng lÆ°á»£ng Ã¡nh sÃ¡ng Ä‘á»ƒ tá»•ng há»£p cháº¥t há»¯u cÆ¡ tá»« cÃ¡c nguyÃªn liá»‡u vÃ´ cÆ¡.\"\n",
        "input_prompt = f\"mÃ´n: Sinh há»c | chá»§ Ä‘á»: Trao Ä‘á»•i cháº¥t | má»©c Ä‘á»™: Nháº­n biáº¿t | ngá»¯ cáº£nh: {test_context}\"\n",
        "\n",
        "# Test vá»›i tham sá»‘ sinh chuáº©n (Beam 5)\n",
        "output = generator(\n",
        "    input_prompt,\n",
        "    max_length=256,\n",
        "    num_beams=5,\n",
        "    length_penalty=1.0\n",
        ")\n",
        "\n",
        "print(f\"\\nğŸ“ INPUT: {input_prompt}\")\n",
        "print(f\"âœ… OUTPUT: {output[0]['generated_text']}\")"
      ],
      "metadata": {
        "id": "powBPY5JQVAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Test mÃ´ hÃ¬nh viT5"
      ],
      "metadata": {
        "id": "IK6WCUAktjkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import re\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from difflib import SequenceMatcher\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Káº¾T Ná»I DRIVE & LOAD MODEL\n",
        "if not os.path.exists('/content/drive'): drive.mount('/content/drive')\n",
        "MODEL_PATH = \"/content/drive/MyDrive/KhoaLuan/model_final/v2/model_vit5_final_ultra\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"â³ Äang táº£i model tá»«: {MODEL_PATH} ...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH).to(DEVICE)\n",
        "print(\"âœ… Há»‡ thá»‘ng Ä‘Ã£ sáºµn sÃ ng!\")\n",
        "\n",
        "# 2. KHO ÄÃP ÃN NHIá»„U (10 MÃ”N Há»ŒC)\n",
        "BACKUP_OPTIONS = {\n",
        "    \"ToÃ¡n há»c\": [\"Sá»‘ há»¯u tá»‰\", \"HÃ m sá»‘ báº­c nháº¥t\", \"Äá»‹nh lÃ­ Pythagore\", \"Tam giÃ¡c Ä‘á»“ng dáº¡ng\", \"Há»‡ phÆ°Æ¡ng trÃ¬nh\", \"Äáº¡o hÃ m\", \"TÃ­ch phÃ¢n\"],\n",
        "    \"Váº­t lÃ½\": [\"Äá»‹nh luáº­t Newton\", \"Äiá»‡n trá»Ÿ\", \"Pháº£n xáº¡ Ã¡nh sÃ¡ng\", \"Dao Ä‘á»™ng cÆ¡\", \"SÃ³ng dá»«ng\", \"DÃ²ng Ä‘iá»‡n xoay chiá»u\"],\n",
        "    \"HÃ³a há»c\": [\"Báº£ng tuáº§n hoÃ n\", \"LiÃªn káº¿t cá»™ng hÃ³a trá»‹\", \"Pháº£n á»©ng tháº¿\", \"Kim loáº¡i kiá»m\", \"Ancol\", \"Polime\", \"Sáº¯t vÃ  há»£p cháº¥t\"],\n",
        "    \"Sinh há»c\": [\"Táº¿ bÃ o nhÃ¢n thá»±c\", \"Quang há»£p\", \"NguyÃªn phÃ¢n\", \"Di truyá»n há»c\", \"Há»‡ sinh thÃ¡i\", \"Chá»n lá»c tá»± nhiÃªn\"],\n",
        "    \"Lá»‹ch sá»­\": [\"Phong trÃ o Cáº§n vÆ°Æ¡ng\", \"CÃ¡ch máº¡ng thÃ¡ng TÃ¡m\", \"Chiáº¿n dá»‹ch Äiá»‡n BiÃªn Phá»§\", \"ToÃ n cáº§u hÃ³a\", \"Chiáº¿n tranh láº¡nh\"],\n",
        "    \"Äá»‹a lÃ½\": [\"Äá»‹a hÃ¬nh nhiá»‡t Ä‘á»›i\", \"GiÃ³ mÃ¹a\", \"Máº­t Ä‘á»™ dÃ¢n sá»‘\", \"Chuyá»ƒn dá»‹ch cÆ¡ cáº¥u kinh táº¿\", \"VÃ¹ng kinh táº¿ trá»ng Ä‘iá»ƒm\"],\n",
        "    \"Tin há»c\": [\"Há»‡ Ä‘iá»u hÃ nh\", \"Máº¡ng mÃ¡y tÃ­nh\", \"TrÃ¬nh duyá»‡t Web\", \"NgÃ´n ngá»¯ láº­p trÃ¬nh\", \"CÆ¡ sá»Ÿ dá»¯ liá»‡u\", \"TrÃ­ tuá»‡ nhÃ¢n táº¡o\"],\n",
        "    \"Ngá»¯ vÄƒn\": [\"Hiá»‡n thá»±c phÃª phÃ¡n\", \"VÄƒn há»c lÃ£ng máº¡n\", \"NhÃ¢n Ä‘áº¡o\", \"TÃ¬nh huá»‘ng truyá»‡n\", \"BÃºt phÃ¡p nghá»‡ thuáº­t\", \"Tá»‘ Há»¯u\", \"Nam Cao\"],\n",
        "    \"CÃ´ng nghá»‡\": [\"Báº£n váº½ ká»¹ thuáº­t\", \"Gia cÃ´ng cÆ¡ khÃ­\", \"Máº¡ch Ä‘iá»‡n Ä‘iá»u khiá»ƒn\", \"Äá»™ng cÆ¡ Ä‘á»‘t trong\", \"NÃ´ng nghiá»‡p cÃ´ng nghá»‡ cao\"],\n",
        "    \"GiÃ¡o dá»¥c Kinh táº¿ vÃ  PhÃ¡p luáº­t\": [\"Thá»‹ trÆ°á»ng\", \"Cung cáº§u\", \"Láº¡m phÃ¡t\", \"Thuáº¿\", \"Quyá»n dÃ¢n sá»±\", \"Hiáº¿n phÃ¡p\", \"PhÃ¡p luáº­t lao Ä‘á»™ng\"]\n",
        "}\n",
        "\n",
        "# 3. CÃC HÃ€M Xá»¬ LÃ LOGIC (Háº¬U Ká»²)\n",
        "def get_smart_options_safe(options_dict, context, subject):\n",
        "    seen_values = set()\n",
        "    final_opts = {}\n",
        "    backups = BACKUP_OPTIONS.get(subject, [\"ÄÃ¡p Ã¡n A\", \"ÄÃ¡p Ã¡n B\"]).copy()\n",
        "    random.shuffle(backups)\n",
        "    for key, value in options_dict.items():\n",
        "        clean_val = value.lower().replace(\".\", \"\").strip()\n",
        "        if clean_val not in seen_values and len(clean_val) > 2:\n",
        "            seen_values.add(clean_val)\n",
        "            final_opts[key] = value\n",
        "        else:\n",
        "            if backups:\n",
        "                new_val = backups.pop()\n",
        "                while new_val.lower() in seen_values and backups:\n",
        "                    new_val = backups.pop()\n",
        "                final_opts[key] = new_val\n",
        "                seen_values.add(new_val.lower())\n",
        "    return dict(sorted(final_opts.items()))\n",
        "\n",
        "def get_best_match(context, options_dict, model_ans_char):\n",
        "    best_key = model_ans_char\n",
        "    highest_score = 0\n",
        "    for key, content in options_dict.items():\n",
        "        match_ratio = SequenceMatcher(None, content, context).ratio()\n",
        "        if match_ratio > highest_score:\n",
        "            highest_score = match_ratio\n",
        "            best_key = key\n",
        "    return best_key if highest_score > 0.5 else model_ans_char\n",
        "\n",
        "def run_test_item(subject, topic, level, context):\n",
        "    input_text = f\"mÃ´n: {subject} | chá»§ Ä‘á»: {topic} | má»©c Ä‘á»™: {level} | ngá»¯ cáº£nh: {context}\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs.input_ids, max_length=320, do_sample=True,\n",
        "            num_beams=3, temperature=0.7, repetition_penalty=1.5,\n",
        "            no_repeat_ngram_size=3, early_stopping=True\n",
        "        )\n",
        "\n",
        "    raw_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    pattern = r\"(?si)question\\s*[:\\-]\\s*(.*?)\\s*options\\s*[:\\-]\\s*(.*?)\\s*answer\\s*[:\\-]\\s*(.*)\"\n",
        "    match = re.search(pattern, raw_output)\n",
        "\n",
        "    if match:\n",
        "        q = match.group(1).strip()\n",
        "        opts_str = match.group(2).strip()\n",
        "        ans_raw = match.group(3).strip()\n",
        "        opts_list = re.findall(r\"([A-D])\\.\\s*(.*?)(?=\\s*[A-D]\\.|$)\", opts_str + \" \", re.DOTALL)\n",
        "        options_dict = {k: v.strip() for k, v in opts_list}\n",
        "\n",
        "        # Xá»­ lÃ½ lÃ m sáº¡ch vÃ  sá»­a lá»—i options\n",
        "        options_dict = get_smart_options_safe(options_dict, context, subject)\n",
        "        model_ans_char = ans_raw[0].upper() if len(ans_raw) > 0 else \"A\"\n",
        "        final_key = get_best_match(context, options_dict, model_ans_char)\n",
        "\n",
        "        # In káº¿t quáº£ ra mÃ n hÃ¬nh\n",
        "        print(f\"ğŸ“Œ [{level.upper()}] {q}\")\n",
        "        print(f\"   \" + \"  |  \".join([f\"{k}. {v}\" for k, v in options_dict.items()]))\n",
        "        print(f\"   âœ… ÄÃP ÃN: {final_key}. {options_dict.get(final_key)}\")\n",
        "    else:\n",
        "        print(f\"âŒ Lá»—i format: {raw_output[:100]}...\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. DANH SÃCH Dá»® LIá»†U Cáº¦N TEST (Báº N Tá»° NHáº¬P VÃ€O ÄÃ‚Y)\n",
        "# ==============================================================================\n",
        "# ==============================================================================\n",
        "# ğŸš€ FULL DATA TEST: 4 MÃ”N x 3 Má»¨C Äá»˜ = 12 MáºªU KIá»‚M THá»¬\n",
        "# ==============================================================================\n",
        "my_test_list = [\n",
        "    # --- 1. Äá»ŠA LÃ (Chuyá»ƒn dá»‹ch cÆ¡ cáº¥u kinh táº¿) ---\n",
        "    {\n",
        "        \"subject\": \"Äá»‹a lÃ½\", \"topic\": \"Chuyá»ƒn dá»‹ch cÆ¡ cáº¥u kinh táº¿ ÄBSH\", \"level\": \"Nháº­n biáº¿t\",\n",
        "        \"context\": \"Äá»“ng báº±ng sÃ´ng Há»“ng lÃ  vÃ¹ng cÃ³ vá»‹ trÃ­ chiáº¿n lÆ°á»£c quan trá»ng, Ä‘Ã³ng gÃ³p lá»›n vÃ o GDP cáº£ nÆ°á»›c. Hiá»‡n nay, cÆ¡ cáº¥u kinh táº¿ cá»§a vÃ¹ng Ä‘ang cÃ³ sá»± chuyá»ƒn dá»‹ch máº¡nh máº½ theo hÆ°á»›ng cÃ´ng nghiá»‡p hÃ³a, hiá»‡n Ä‘áº¡i hÃ³a. Tá»· trá»ng ngÃ nh nÃ´ng, lÃ¢m nghiá»‡p vÃ  thá»§y sáº£n cÃ³ xu hÆ°á»›ng giáº£m, trong khi tá»· trá»ng ngÃ nh cÃ´ng nghiá»‡p, xÃ¢y dá»±ng vÃ  dá»‹ch vá»¥ tÄƒng lÃªn nhanh chÃ³ng. Tuy nhiÃªn, sá»± chuyá»ƒn dá»‹ch nÃ y váº«n cÃ²n cháº­m so vá»›i tiá»m nÄƒng thá»±c táº¿. NguyÃªn nhÃ¢n chá»§ yáº¿u lÃ  do káº¿t cáº¥u háº¡ táº§ng chÆ°a Ä‘á»“ng bá»™, cháº¥t lÆ°á»£ng nguá»“n lao Ä‘á»™ng chÆ°a Ä‘Ã¡p á»©ng Ä‘Æ°á»£c yÃªu cáº§u cá»§a cÃ¡c ngÃ nh cÃ´ng nghá»‡ cao. BÃªn cáº¡nh Ä‘Ã³, sá»©c Ã©p vá» máº­t Ä‘á»™ dÃ¢n sá»‘ quÃ¡ cao (lá»›n nháº¥t cáº£ nÆ°á»›c) cÅ©ng gÃ¢y ra nhiá»u khÃ³ khÄƒn trong viá»‡c giáº£i quyáº¿t viá»‡c lÃ m vÃ  báº£o vá»‡ tÃ i nguyÃªn mÃ´i trÆ°á»ng bá»n vá»¯ng cho toÃ n vÃ¹ng.\"\n",
        "    },\n",
        "    {\n",
        "        \"subject\": \"Äá»‹a lÃ½\", \"topic\": \"Chuyá»ƒn dá»‹ch cÆ¡ cáº¥u kinh táº¿ ÄBSH\", \"level\": \"ThÃ´ng hiá»ƒu\",\n",
        "        \"context\": \"Äá»“ng báº±ng sÃ´ng Há»“ng lÃ  vÃ¹ng cÃ³ vá»‹ trÃ­ chiáº¿n lÆ°á»£c quan trá»ng, Ä‘Ã³ng gÃ³p lá»›n vÃ o GDP cáº£ nÆ°á»›c. Hiá»‡n nay, cÆ¡ cáº¥u kinh táº¿ cá»§a vÃ¹ng Ä‘ang cÃ³ sá»± chuyá»ƒn dá»‹ch máº¡nh máº½ theo hÆ°á»›ng cÃ´ng nghiá»‡p hÃ³a, hiá»‡n Ä‘áº¡i hÃ³a. Tá»· trá»ng ngÃ nh nÃ´ng, lÃ¢m nghiá»‡p vÃ  thá»§y sáº£n cÃ³ xu hÆ°á»›ng giáº£m, trong khi tá»· trá»ng ngÃ nh cÃ´ng nghiá»‡p, xÃ¢y dá»±ng vÃ  dá»‹ch vá»¥ tÄƒng lÃªn nhanh chÃ³ng. Tuy nhiÃªn, sá»± chuyá»ƒn dá»‹ch nÃ y váº«n cÃ²n cháº­m so vá»›i tiá»m nÄƒng thá»±c táº¿. NguyÃªn nhÃ¢n chá»§ yáº¿u lÃ  do káº¿t cáº¥u háº¡ táº§ng chÆ°a Ä‘á»“ng bá»™, cháº¥t lÆ°á»£ng nguá»“n lao Ä‘á»™ng chÆ°a Ä‘Ã¡p á»©ng Ä‘Æ°á»£c yÃªu cáº§u cá»§a cÃ¡c ngÃ nh cÃ´ng nghá»‡ cao. BÃªn cáº¡nh Ä‘Ã³, sá»©c Ã©p vá» máº­t Ä‘á»™ dÃ¢n sá»‘ quÃ¡ cao (lá»›n nháº¥t cáº£ nÆ°á»›c) cÅ©ng gÃ¢y ra nhiá»u khÃ³ khÄƒn trong viá»‡c giáº£i quyáº¿t viá»‡c lÃ m vÃ  báº£o vá»‡ tÃ i nguyÃªn mÃ´i trÆ°á»ng bá»n vá»¯ng cho toÃ n vÃ¹ng.\"\n",
        "    },\n",
        "    {\n",
        "        \"subject\": \"Äá»‹a lÃ½\", \"topic\": \"Chuyá»ƒn dá»‹ch cÆ¡ cáº¥u kinh táº¿ ÄBSH\", \"level\": \"Váº­n dá»¥ng\",\n",
        "        \"context\": \"Äá»“ng báº±ng sÃ´ng Há»“ng lÃ  vÃ¹ng cÃ³ vá»‹ trÃ­ chiáº¿n lÆ°á»£c quan trá»ng, Ä‘Ã³ng gÃ³p lá»›n vÃ o GDP cáº£ nÆ°á»›c. Hiá»‡n nay, cÆ¡ cáº¥u kinh táº¿ cá»§a vÃ¹ng Ä‘ang cÃ³ sá»± chuyá»ƒn dá»‹ch máº¡nh máº½ theo hÆ°á»›ng cÃ´ng nghiá»‡p hÃ³a, hiá»‡n Ä‘áº¡i hÃ³a. Tá»· trá»ng ngÃ nh nÃ´ng, lÃ¢m nghiá»‡p vÃ  thá»§y sáº£n cÃ³ xu hÆ°á»›ng giáº£m, trong khi tá»· trá»ng ngÃ nh cÃ´ng nghiá»‡p, xÃ¢y dá»±ng vÃ  dá»‹ch vá»¥ tÄƒng lÃªn nhanh chÃ³ng. Tuy nhiÃªn, sá»± chuyá»ƒn dá»‹ch nÃ y váº«n cÃ²n cháº­m so vá»›i tiá»m nÄƒng thá»±c táº¿. NguyÃªn nhÃ¢n chá»§ yáº¿u lÃ  do káº¿t cáº¥u háº¡ táº§ng chÆ°a Ä‘á»“ng bá»™, cháº¥t lÆ°á»£ng nguá»“n lao Ä‘á»™ng chÆ°a Ä‘Ã¡p á»©ng Ä‘Æ°á»£c yÃªu cáº§u cá»§a cÃ¡c ngÃ nh cÃ´ng nghá»‡ cao. BÃªn cáº¡nh Ä‘Ã³, sá»©c Ã©p vá» máº­t Ä‘á»™ dÃ¢n sá»‘ quÃ¡ cao (lá»›n nháº¥t cáº£ nÆ°á»›c) cÅ©ng gÃ¢y ra nhiá»u khÃ³ khÄƒn trong viá»‡c giáº£i quyáº¿t viá»‡c lÃ m vÃ  báº£o vá»‡ tÃ i nguyÃªn mÃ´i trÆ°á»ng bá»n vá»¯ng cho toÃ n vÃ¹ng.\"\n",
        "    },\n",
        "\n",
        "    # --- 2. SINH Há»ŒC (Cáº¥u táº¡o vÃ  chá»©c nÄƒng cá»§a Ti thá»ƒ) ---\n",
        "    {\n",
        "        \"subject\": \"Sinh há»c\", \"topic\": \"Ti thá»ƒ trong táº¿ bÃ o\", \"level\": \"Nháº­n biáº¿t\",\n",
        "        \"context\": \"Ti thá»ƒ lÃ  má»™t trong nhá»¯ng bÃ o quan quan trá»ng nháº¥t trong táº¿ bÃ o nhÃ¢n thá»±c, Ä‘Æ°á»£c bao bá»c bá»Ÿi hai lá»›p mÃ ng sinh cháº¥t. MÃ ng ngoÃ i trÆ¡n nháºµn, trong khi mÃ ng trong gáº¥p náº¿p táº¡o thÃ nh cÃ¡c mÃ o, nÆ¡i chá»©a cÃ¡c enzyme hÃ´ háº¥p. BÃªn trong ti thá»ƒ lÃ  cháº¥t ná»n chá»©a DNA vÃ  ribosome riÃªng, cho phÃ©p chÃºng tá»± nhÃ¢n Ä‘Ã´i Ä‘á»™c láº­p vá»›i sá»± phÃ¢n chia cá»§a táº¿ bÃ o. Chá»©c nÄƒng chÃ­nh cá»§a ti thá»ƒ lÃ  nÆ¡i diá»…n ra quÃ¡ trÃ¬nh hÃ´ háº¥p táº¿ bÃ o, chuyá»ƒn hÃ³a nÄƒng lÆ°á»£ng tá»« cÃ¡c há»£p cháº¥t há»¯u cÆ¡ thÃ nh ATP â€“ nguá»“n nÄƒng lÆ°á»£ng trá»±c tiáº¿p cho má»i hoáº¡t Ä‘á»™ng sá»‘ng. Sá»‘ lÆ°á»£ng ti thá»ƒ trong má»—i loáº¡i táº¿ bÃ o lÃ  khÃ´ng giá»‘ng nhau, phá»¥ thuá»™c vÃ o nhu cáº§u nÄƒng lÆ°á»£ng cá»§a loáº¡i táº¿ bÃ o Ä‘Ã³. VÃ­ dá»¥, táº¿ bÃ o cÆ¡ tim hoáº·c táº¿ bÃ o gan thÆ°á»ng chá»©a hÃ ng nghÃ¬n ti thá»ƒ Ä‘á»ƒ Ä‘áº£m báº£o duy trÃ¬ cÃ´ng nÄƒng hoáº¡t Ä‘á»™ng liÃªn tá»¥c.\"\n",
        "    },\n",
        "    {\n",
        "        \"subject\": \"Sinh há»c\", \"topic\": \"Ti thá»ƒ trong táº¿ bÃ o\", \"level\": \"ThÃ´ng hiá»ƒu\",\n",
        "        \"context\": \"Ti thá»ƒ lÃ  má»™t trong nhá»¯ng bÃ o quan quan trá»ng nháº¥t trong táº¿ bÃ o nhÃ¢n thá»±c, Ä‘Æ°á»£c bao bá»c bá»Ÿi hai lá»›p mÃ ng sinh cháº¥t. MÃ ng ngoÃ i trÆ¡n nháºµn, trong khi mÃ ng trong gáº¥p náº¿p táº¡o thÃ nh cÃ¡c mÃ o, nÆ¡i chá»©a cÃ¡c enzyme hÃ´ háº¥p. BÃªn trong ti thá»ƒ lÃ  cháº¥t ná»n chá»©a DNA vÃ  ribosome riÃªng, cho phÃ©p chÃºng tá»± nhÃ¢n Ä‘Ã´i Ä‘á»™c láº­p vá»›i sá»± phÃ¢n chia cá»§a táº¿ bÃ o. Chá»©c nÄƒng chÃ­nh cá»§a ti thá»ƒ lÃ  nÆ¡i diá»…n ra quÃ¡ trÃ¬nh hÃ´ háº¥p táº¿ bÃ o, chuyá»ƒn hÃ³a nÄƒng lÆ°á»£ng tá»« cÃ¡c há»£p cháº¥t há»¯u cÆ¡ thÃ nh ATP â€“ nguá»“n nÄƒng lÆ°á»£ng trá»±c tiáº¿p cho má»i hoáº¡t Ä‘á»™ng sá»‘ng. Sá»‘ lÆ°á»£ng ti thá»ƒ trong má»—i loáº¡i táº¿ bÃ o lÃ  khÃ´ng giá»‘ng nhau, phá»¥ thuá»™c vÃ o nhu cáº§u nÄƒng lÆ°á»£ng cá»§a loáº¡i táº¿ bÃ o Ä‘Ã³. VÃ­ dá»¥, táº¿ bÃ o cÆ¡ tim hoáº·c táº¿ bÃ o gan thÆ°á»ng chá»©a hÃ ng nghÃ¬n ti thá»ƒ Ä‘á»ƒ Ä‘áº£m báº£o duy trÃ¬ cÃ´ng nÄƒng hoáº¡t Ä‘á»™ng liÃªn tá»¥c.\"\n",
        "    },\n",
        "    {\n",
        "        \"subject\": \"Sinh há»c\", \"topic\": \"Ti thá»ƒ trong táº¿ bÃ o\", \"level\": \"Váº­n dá»¥ng\",\n",
        "        \"context\": \"Ti thá»ƒ lÃ  má»™t trong nhá»¯ng bÃ o quan quan trá»ng nháº¥t trong táº¿ bÃ o nhÃ¢n thá»±c, Ä‘Æ°á»£c bao bá»c bá»Ÿi hai lá»›p mÃ ng sinh cháº¥t. MÃ ng ngoÃ i trÆ¡n nháºµn, trong khi mÃ ng trong gáº¥p náº¿p táº¡o thÃ nh cÃ¡c mÃ o, nÆ¡i chá»©a cÃ¡c enzyme hÃ´ háº¥p. BÃªn trong ti thá»ƒ lÃ  cháº¥t ná»n chá»©a DNA vÃ  ribosome riÃªng, cho phÃ©p chÃºng tá»± nhÃ¢n Ä‘Ã´i Ä‘á»™c láº­p vá»›i sá»± phÃ¢n chia cá»§a táº¿ bÃ o. Chá»©c nÄƒng chÃ­nh cá»§a ti thá»ƒ lÃ  nÆ¡i diá»…n ra quÃ¡ trÃ¬nh hÃ´ háº¥p táº¿ bÃ o, chuyá»ƒn hÃ³a nÄƒng lÆ°á»£ng tá»« cÃ¡c há»£p cháº¥t há»¯u cÆ¡ thÃ nh ATP â€“ nguá»“n nÄƒng lÆ°á»£ng trá»±c tiáº¿p cho má»i hoáº¡t Ä‘á»™ng sá»‘ng. Sá»‘ lÆ°á»£ng ti thá»ƒ trong má»—i loáº¡i táº¿ bÃ o lÃ  khÃ´ng giá»‘ng nhau, phá»¥ thuá»™c vÃ o nhu cáº§u nÄƒng lÆ°á»£ng cá»§a loáº¡i táº¿ bÃ o Ä‘Ã³. VÃ­ dá»¥, táº¿ bÃ o cÆ¡ tim hoáº·c táº¿ bÃ o gan thÆ°á»ng chá»©a hÃ ng nghÃ¬n ti thá»ƒ Ä‘á»ƒ Ä‘áº£m báº£o duy trÃ¬ cÃ´ng nÄƒng hoáº¡t Ä‘á»™ng liÃªn tá»¥c.\"\n",
        "    },\n",
        "\n",
        "    # --- 3. TIN Há»ŒC (Giao thá»©c HTTPS) ---\n",
        "    {\n",
        "        \"subject\": \"Tin há»c\", \"topic\": \"Giao thá»©c HTTPS\", \"level\": \"Nháº­n biáº¿t\",\n",
        "        \"context\": \"Trong ká»· nguyÃªn sá»‘, an toÃ n thÃ´ng tin lÃ  Æ°u tiÃªn hÃ ng Ä‘áº§u khi thá»±c hiá»‡n cÃ¡c giao dá»‹ch trÃªn máº¡ng Internet. Giao thá»©c HTTPS (Hypertext Transfer Protocol Secure) Ä‘Ã£ ra Ä‘á»i nhÆ° má»™t phiÃªn báº£n báº£o máº­t cá»§a HTTP truyá»n thá»‘ng. HTTPS hoáº¡t Ä‘á»™ng báº±ng cÃ¡ch káº¿t há»£p giao thá»©c HTTP vá»›i chá»©ng chá»‰ SSL/TLS Ä‘á»ƒ mÃ£ hÃ³a dá»¯ liá»‡u truyá»n Ä‘i giá»¯a trÃ¬nh duyá»‡t cá»§a ngÆ°á»i dÃ¹ng vÃ  mÃ¡y chá»§ web. QuÃ¡ trÃ¬nh nÃ y Ä‘áº£m báº£o ráº±ng cÃ¡c thÃ´ng tin nháº¡y cáº£m nhÆ° máº­t kháº©u, tÃ i khoáº£n ngÃ¢n hÃ ng hoáº·c dá»¯ liá»‡u cÃ¡ nhÃ¢n khÃ´ng bá»‹ káº» xáº¥u Ä‘Ã¡nh cáº¯p hoáº·c thay Ä‘á»•i trÃªn Ä‘Æ°á»ng truyá»n. Má»™t website sá»­ dá»¥ng HTTPS thÆ°á»ng cÃ³ biá»ƒu tÆ°á»£ng á»• khÃ³a xanh trÃªn thanh Ä‘á»‹a chá»‰, giÃºp tÄƒng Ä‘á»™ tin cáº­y cho ngÆ°á»i dÃ¹ng.\"\n",
        "    },\n",
        "    {\n",
        "        \"subject\": \"Tin há»c\", \"topic\": \"Giao thá»©c HTTPS\", \"level\": \"ThÃ´ng hiá»ƒu\",\n",
        "        \"context\": \"Trong ká»· nguyÃªn sá»‘, an toÃ n thÃ´ng tin lÃ  Æ°u tiÃªn hÃ ng Ä‘áº§u khi thá»±c hiá»‡n cÃ¡c giao dá»‹ch trÃªn máº¡ng Internet. Giao thá»©c HTTPS (Hypertext Transfer Protocol Secure) Ä‘Ã£ ra Ä‘á»i nhÆ° má»™t phiÃªn báº£n báº£o máº­t cá»§a HTTP truyá»n thá»‘ng. HTTPS hoáº¡t Ä‘á»™ng báº±ng cÃ¡ch káº¿t há»£p giao thá»©c HTTP vá»›i chá»©ng chá»‰ SSL/TLS Ä‘á»ƒ mÃ£ hÃ³a dá»¯ liá»‡u truyá»n Ä‘i giá»¯a trÃ¬nh duyá»‡t cá»§a ngÆ°á»i dÃ¹ng vÃ  mÃ¡y chá»§ web. QuÃ¡ trÃ¬nh nÃ y Ä‘áº£m báº£o ráº±ng cÃ¡c thÃ´ng tin nháº¡y cáº£m nhÆ° máº­t kháº©u, tÃ i khoáº£n ngÃ¢n hÃ ng hoáº·c dá»¯ liá»‡u cÃ¡ nhÃ¢n khÃ´ng bá»‹ káº» xáº¥u Ä‘Ã¡nh cáº¯p hoáº·c thay Ä‘á»•i trÃªn Ä‘Æ°á»ng truyá»n. Má»™t website sá»­ dá»¥ng HTTPS thÆ°á»ng cÃ³ biá»ƒu tÆ°á»£ng á»• khÃ³a xanh trÃªn thanh Ä‘á»‹a chá»‰, giÃºp tÄƒng Ä‘á»™ tin cáº­y cho ngÆ°á»i dÃ¹ng.\"\n",
        "    },\n",
        "    {\n",
        "        \"subject\": \"Tin há»c\", \"topic\": \"Giao thá»©c HTTPS\", \"level\": \"Váº­n dá»¥ng\",\n",
        "        \"context\": \"Trong ká»· nguyÃªn sá»‘, an toÃ n thÃ´ng tin lÃ  Æ°u tiÃªn hÃ ng Ä‘áº§u khi thá»±c hiá»‡n cÃ¡c giao dá»‹ch trÃªn máº¡ng Internet. Giao thá»©c HTTPS (Hypertext Transfer Protocol Secure) Ä‘Ã£ ra Ä‘á»i nhÆ° má»™t phiÃªn báº£n báº£o máº­t cá»§a HTTP truyá»n thá»‘ng. HTTPS hoáº¡t Ä‘á»™ng báº±ng cÃ¡ch káº¿t há»£p giao thá»©c HTTP with SSL/TLS certificate to encrypt data transmitted between browser and web server. QuÃ¡ trÃ¬nh nÃ y Ä‘áº£m báº£o ráº±ng cÃ¡c thÃ´ng tin nháº¡y cáº£m nhÆ° máº­t kháº©u, tÃ i khoáº£n ngÃ¢n hÃ ng hoáº·c dá»¯ liá»‡u cÃ¡ nhÃ¢n khÃ´ng bá»‹ káº» xáº¥u Ä‘Ã¡nh cáº¯p hoáº·c thay Ä‘á»•i trÃªn Ä‘Æ°á»ng truyá»n. Viá»‡c triá»ƒn khai HTTPS khÃ´ng chá»‰ báº£o vá»‡ quyá»n riÃªng tÆ° mÃ  cÃ²n lÃ  má»™t tiÃªu chuáº©n quan trá»ng Ä‘á»ƒ cÃ¡c cÃ´ng cá»¥ tÃ¬m kiáº¿m xáº¿p háº¡ng uy tÃ­n cho trang web.\"\n",
        "    },\n",
        "\n",
        "    # --- 4. NGá»® VÄ‚N (Vá»£ nháº·t) ---\n",
        "    {\n",
        "        \"subject\": \"Ngá»¯ vÄƒn\", \"topic\": \"GiÃ¡ trá»‹ nhÃ¢n Ä‘áº¡o trong Vá»£ nháº·t\", \"level\": \"Nháº­n biáº¿t\",\n",
        "        \"context\": \"Truyá»‡n ngáº¯n 'Vá»£ nháº·t' cá»§a nhÃ  vÄƒn Kim LÃ¢n khÃ´ng chá»‰ kháº¯c há»a bá»©c tranh thÃª tháº£m cá»§a náº¡n Ä‘Ã³i nÄƒm 1945 mÃ  cÃ²n tá»a sÃ¡ng váº» Ä‘áº¹p cá»§a tÃ¬nh ngÆ°á»i vÃ  khÃ¡t vá»ng sá»‘ng mÃ£nh liá»‡t. Trong hoÃ n cáº£nh cÃ¡i cháº¿t bá»§a vÃ¢y, nhÃ¢n váº­t TrÃ ng váº«n liá»u lÄ©nh Ä‘Æ°a má»™t ngÆ°á»i Ä‘Ã n bÃ  xa láº¡ vá» lÃ m vá»£. HÃ nh Ä‘á»™ng nÃ y khÃ´ng pháº£i lÃ  sá»± bá»“ng bá»™t cá»§a báº£n nÄƒng mÃ  xuáº¥t phÃ¡t tá»« lÃ²ng nhÃ¢n háº­u vÃ  niá»m tin vÃ o tÆ°Æ¡ng lai. Sá»± hiá»‡n diá»‡n cá»§a nÃ ng dÃ¢u má»›i Ä‘Ã£ lÃ m thay Ä‘á»•i hoÃ n toÃ n khÃ´ng khÃ­ u Ã¡m cá»§a xÃ³m ngá»¥ cÆ° vÃ  Ä‘em láº¡i sá»©c sá»‘ng cho bÃ  cá»¥ Tá»©. Qua Ä‘Ã³, tÃ¡c giáº£ kháº³ng Ä‘á»‹nh má»™t chÃ¢n lÃ½ nghá»‡ thuáº­t sÃ¢u sáº¯c: dÃ¹ á»Ÿ bÃªn bá» vá»±c cá»§a cÃ¡i cháº¿t, con ngÆ°á»i váº«n khÃ´ng ngá»«ng khÃ¡t khao háº¡nh phÃºc, váº«n Ä‘Ã¹m bá»c vÃ  yÃªu thÆ°Æ¡ng nhau Ä‘á»ƒ vÆ°á»£t qua nghá»‹ch cáº£nh. ÄÃ³ chÃ­nh lÃ  giÃ¡ trá»‹ nhÃ¢n Ä‘áº¡o cao cáº£.\"\n",
        "    },\n",
        "    {\n",
        "        \"subject\": \"Ngá»¯ vÄƒn\", \"topic\": \"GiÃ¡ trá»‹ nhÃ¢n Ä‘áº¡o trong Vá»£ nháº·t\", \"level\": \"ThÃ´ng hiá»ƒu\",\n",
        "        \"context\": \"Truyá»‡n ngáº¯n 'Vá»£ nháº·t' cá»§a nhÃ  vÄƒn Kim LÃ¢n khÃ´ng chá»‰ kháº¯c há»a bá»©c tranh thÃª tháº£m cá»§a náº¡n Ä‘Ã³i nÄƒm 1945 mÃ  cÃ²n tá»a sÃ¡ng váº» Ä‘áº¹p cá»§a tÃ¬nh ngÆ°á»i vÃ  khÃ¡t vá»ng sá»‘ng mÃ£nh liá»‡t. Trong hoÃ n cáº£nh cÃ¡i cháº¿t bá»§a vÃ¢y, nhÃ¢n váº­t TrÃ ng váº«n liá»u lÄ©nh Ä‘Æ°a má»™t ngÆ°á»i Ä‘Ã n bÃ  xa láº¡ vá» lÃ m vá»£. HÃ nh Ä‘á»™ng nÃ y khÃ´ng pháº£i lÃ  sá»± bá»“ng bá»™t cá»§a báº£n nÄƒng mÃ  xuáº¥t phÃ¡t tá»« lÃ²ng nhÃ¢n háº­u vÃ  niá»m tin vÃ o tÆ°Æ¡ng lai. Sá»± hiá»‡n diá»‡n cá»§a nÃ ng dÃ¢u má»›i Ä‘Ã£ lÃ m thay Ä‘á»•i hoÃ n toÃ n khÃ´ng khÃ­ u Ã¡m cá»§a xÃ³m ngá»¥ cÆ° vÃ  Ä‘em láº¡i sá»©c sá»‘ng cho bÃ  cá»¥ Tá»©. Qua Ä‘Ã³, tÃ¡c giáº£ kháº³ng Ä‘á»‹nh má»™t chÃ¢n lÃ½ nghá»‡ thuáº­t sÃ¢u sáº¯c: dÃ¹ á»Ÿ bÃªn bá» vá»±c cá»§a cÃ¡i cháº¿t, con ngÆ°á»i váº«n khÃ´ng ngá»«ng khÃ¡t khao háº¡nh phÃºc, váº«n Ä‘Ã¹m bá»c vÃ  yÃªu thÆ°Æ¡ng nhau Ä‘á»ƒ vÆ°á»£t qua nghá»‹ch cáº£nh. ÄÃ³ chÃ­nh lÃ  giÃ¡ trá»‹ nhÃ¢n Ä‘áº¡o cao cáº£.\"\n",
        "    },\n",
        "    {\n",
        "        \"subject\": \"Ngá»¯ vÄƒn\", \"topic\": \"GiÃ¡ trá»‹ nhÃ¢n Ä‘áº¡o trong Vá»£ nháº·t\", \"level\": \"Váº­n dá»¥ng\",\n",
        "        \"context\": \"Truyá»‡n ngáº¯n 'Vá»£ nháº·t' cá»§a nhÃ  vÄƒn Kim LÃ¢n khÃ´ng chá»‰ kháº¯c há»a bá»©c tranh thÃª tháº£m cá»§a náº¡n Ä‘Ã³i nÄƒm 1945 mÃ  cÃ²n tá»a sÃ¡ng váº» Ä‘áº¹p cá»§a tÃ¬nh ngÆ°á»i vÃ  khÃ¡t vá»ng sá»‘ng mÃ£nh liá»‡t. Trong hoÃ n cáº£nh cÃ¡i cháº¿t bá»§a vÃ¢y, nhÃ¢n váº­t TrÃ ng váº«n liá»u lÄ©nh Ä‘Æ°a má»™t ngÆ°á»i Ä‘Ã n bÃ  xa láº¡ vá» lÃ m vá»£. HÃ nh Ä‘á»™ng nÃ y khÃ´ng pháº£i lÃ  sá»± bá»“ng bá»™t cá»§a báº£n nÄƒng mÃ  xuáº¥t phÃ¡t tá»« lÃ²ng nhÃ¢n háº­u vÃ  niá»m tin vÃ o tÆ°Æ¡ng lai. Sá»± hiá»‡n diá»‡n cá»§a nÃ ng dÃ¢u má»›i Ä‘Ã£ lÃ m thay Ä‘á»•i hoÃ n toÃ n khÃ´ng khÃ­ u Ã¡m cá»§a xÃ³m ngá»¥ cÆ° vÃ  Ä‘em láº¡i sá»©c sá»‘ng cho bÃ  cá»¥ Tá»©. Qua Ä‘Ã³, tÃ¡c giáº£ kháº³ng Ä‘á»‹nh má»™t chÃ¢n lÃ½ nghá»‡ thuáº­t sÃ¢u sáº¯c: dÃ¹ á»Ÿ bÃªn bá» vá»±c cá»§a cÃ¡i cháº¿t, con ngÆ°á»i váº«n khÃ´ng ngá»«ng khÃ¡t khao háº¡nh phÃºc, váº«n Ä‘Ã¹m bá»c vÃ  yÃªu thÆ°Æ¡ng nhau Ä‘á»ƒ vÆ°á»£t qua nghá»‹ch cáº£nh. ÄÃ³ chÃ­nh lÃ  giÃ¡ trá»‹ nhÃ¢n Ä‘áº¡o cao cáº£.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# CHáº Y LOOP QUA DANH SÃCH 12 CÃ‚U Há»I\n",
        "for item in my_test_list:\n",
        "    run_test_item(item['subject'], item['topic'], item['level'], item['context'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql3wFxHRwm_j",
        "outputId": "82f73934-cee1-4571-a304-16305df27a77"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â³ Äang táº£i model tá»«: /content/drive/MyDrive/KhoaLuan/model_final/v2/model_vit5_final_ultra ...\n",
            "âœ… Há»‡ thá»‘ng Ä‘Ã£ sáºµn sÃ ng!\n",
            "ğŸ“Œ [NHáº¬N BIáº¾T] VÃ¹ng nÃ o cÃ³ vá»‹ trÃ­ chiáº¿n lÆ°á»£c quan trá»ng, Ä‘Ã³ng gÃ³p lá»›n vÃ o GDP cáº£ nÆ°á»›c?\n",
            "   A. TÃ¢y NguyÃªn.  |  B. Äá»“ng báº±ng sÃ´ng Há»“ng.  |  C. Trung du vÃ  miá»n nÃºi Báº¯c Bá»™.  |  D. DuyÃªn háº£i Nam Trung Bá»™.\n",
            "   âœ… ÄÃP ÃN: B. Äá»“ng báº±ng sÃ´ng Há»“ng.\n",
            "--------------------------------------------------\n",
            "ğŸ“Œ [THÃ”NG HIá»‚U] NguyÃªn nhÃ¢n chá»§ yáº¿u khiáº¿n tá»‰ trá»ng ngÃ nh nÃ´ng, lÃ¢m nghiá»‡p vÃ  thá»§y sáº£n á»Ÿ ÄBSH cÃ²n cháº­m lÃ  gÃ¬?\n",
            "   A. Thiáº¿u nguá»“n lao Ä‘á»™ng  |  B. Thiáº¿u tÃ i nguyÃªn rá»«ng  |  C. Thiáº¿u vá»‘n Ä‘áº§u tÆ°  |  D. Káº¿t cáº¥u háº¡ táº§ng chÆ°a Ä‘á»“ng bá»™, cháº¥t lÆ°á»£ng nguá»“n lao Äá»™ng chÆ°a Ä‘Ã¡p á»©ng Ä‘Æ°á»£c yÃªu cáº§u cá»§a cÃ¡c ngÃ nh cÃ´ng nghá»‡ cao\n",
            "   âœ… ÄÃP ÃN: D. Káº¿t cáº¥u háº¡ táº§ng chÆ°a Ä‘á»“ng bá»™, cháº¥t lÆ°á»£ng nguá»“n lao Äá»™ng chÆ°a Ä‘Ã¡p á»©ng Ä‘Æ°á»£c yÃªu cáº§u cá»§a cÃ¡c ngÃ nh cÃ´ng nghá»‡ cao\n",
            "--------------------------------------------------\n",
            "ğŸ“Œ [Váº¬N Dá»¤NG] NguyÃªn nhÃ¢n chá»§ yáº¿u gÃ¢y ra sá»± chuyá»ƒn dá»‹ch cÆ¡ cáº¥u kinh táº¿ cháº­m á»Ÿ Äá»“ng báº±ng sÃ´ng Há»“ng lÃ  gÃ¬?\n",
            "   A. Thiáº¿u nguá»“n lao Ä‘á»™ng  |  B. Thiáº¿u tÃ i nguyÃªn khoÃ¡ng sáº£n  |  C. Sá»‘ lÆ°á»£ng lao Ä‘á»™ng chÆ°a Ä‘á»“ng bá»™ chÆ°a Ä‘Ã¡p á»©ng Ä‘Æ°á»£c yÃªu cáº§u cá»§a cÃ¡c ngÃ nh cÃ´ng nghá»‡ cao  |  D. ChÃ­nh sÃ¡ch háº¡n cháº¿ nháº­p kháº©u hÃ ng hÃ³a\n",
            "   âœ… ÄÃP ÃN: C. Sá»‘ lÆ°á»£ng lao Ä‘á»™ng chÆ°a Ä‘á»“ng bá»™ chÆ°a Ä‘Ã¡p á»©ng Ä‘Æ°á»£c yÃªu cáº§u cá»§a cÃ¡c ngÃ nh cÃ´ng nghá»‡ cao\n",
            "--------------------------------------------------\n",
            "ğŸ“Œ [NHáº¬N BIáº¾T] BÃ o quan nÃ o trong táº¿ bÃ o nhÃ¢n thá»±c Ä‘Æ°á»£c bao bá»c bá»Ÿi hai lá»›p mÃ ng sinh cháº¥t?\n",
            "   A. Ti thá»ƒ  |  B. RibÃ´xÃ´m  |  C. LizÃ´xÃ´m  |  D. NhÃ¢n táº¿ bÃ o\n",
            "   âœ… ÄÃP ÃN: A. Ti thá»ƒ\n",
            "--------------------------------------------------\n",
            "ğŸ“Œ [THÃ”NG HIá»‚U] Chá»©c nÄƒng chÃ­nh cá»§a ti thá»ƒ lÃ  gÃ¬?\n",
            "   A. NÆ¡i diá»…n ra quÃ¡ trÃ¬nh hÃ´ háº¥p táº¿ bÃ o, chuyá»ƒn hÃ³a nÄƒng lÆ°á»£ng tá»« cÃ¡c há»£p cháº¥t há»¯u cÆ¡ thÃ nh ATP  |  B. NÆ¡i tá»•ng há»£p prÃ´tÃªin  |  C. NÆ¡i á»Ÿ cá»§a táº¿ bÃ o  |  D. NÆ¡i phÃ¢n chia táº¿ bÃ o cho táº¿ bÃ o\n",
            "   âœ… ÄÃP ÃN: A. NÆ¡i diá»…n ra quÃ¡ trÃ¬nh hÃ´ háº¥p táº¿ bÃ o, chuyá»ƒn hÃ³a nÄƒng lÆ°á»£ng tá»« cÃ¡c há»£p cháº¥t há»¯u cÆ¡ thÃ nh ATP\n",
            "--------------------------------------------------\n",
            "ğŸ“Œ [Váº¬N Dá»¤NG] Chá»©c nÄƒng chÃ­nh cá»§a ti thá»ƒ lÃ  gÃ¬?\n",
            "   A. NÆ¡i diá»…n ra quÃ¡ trÃ¬nh hÃ´ háº¥p táº¿ bÃ o, chuyá»ƒn hÃ³a nÄƒng lÆ°á»£ng tá»« cÃ¡c há»£p cháº¥t há»¯u cÆ¡ thÃ nh ATP  |  B. NÆ¡i mÃ ng sinh cháº¥t tá»•ng há»£p ATP  |  C. NÆ¡i tá»•ng há»£p prÃ´tÃªin  |  D. NÆ¡i chá»©a ARN vÃ  ARN\n",
            "   âœ… ÄÃP ÃN: A. NÆ¡i diá»…n ra quÃ¡ trÃ¬nh hÃ´ háº¥p táº¿ bÃ o, chuyá»ƒn hÃ³a nÄƒng lÆ°á»£ng tá»« cÃ¡c há»£p cháº¥t há»¯u cÆ¡ thÃ nh ATP\n",
            "--------------------------------------------------\n",
            "ğŸ“Œ [NHáº¬N BIáº¾T] Giao thá»©c HTTPS Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ lÃ m gÃ¬?\n",
            "   A. MÃ£ hÃ³a dá»¯ liá»‡u truyá»n Ä‘i giá»¯a trÃ¬nh duyá»‡t cá»§a ngÆ°á»i dÃ¹ng vÃ  mÃ¡y chá»§ web  |  B. Chá»‰ truyá»n táº£i vÄƒn báº£n  |  C. TÄƒng tá»‘c Ä‘á»™ truyá»n táº£i  |  D. Thay Ä‘á»•i máº­t kháº©u Wi-Fi\n",
            "   âœ… ÄÃP ÃN: A. MÃ£ hÃ³a dá»¯ liá»‡u truyá»n Ä‘i giá»¯a trÃ¬nh duyá»‡t cá»§a ngÆ°á»i dÃ¹ng vÃ  mÃ¡y chá»§ web\n",
            "--------------------------------------------------\n",
            "ğŸ“Œ [THÃ”NG HIá»‚U] Giao thá»©c HTTPS hoáº¡t Ä‘á»™ng dá»±a trÃªn nguyÃªn táº¯c nÃ o?\n",
            "   A. Chá»‰ sá»­ dá»¥ng máº¡ng Internet  |  B. Káº¿t há»£p giao thá»©c HTTP vá»›i chá»©ng chá»‰ SSL/TLS  |  C. Chá»‰ dÃ¹ng cho mÃ¡y tÃ­nh cÃ¡ nhÃ¢n  |  D. Sá»­ dá»¥ng cÃ¡c giao dá»‹ch trá»±c tuyáº¿n\n",
            "   âœ… ÄÃP ÃN: B. Káº¿t há»£p giao thá»©c HTTP vá»›i chá»©ng chá»‰ SSL/TLS\n",
            "--------------------------------------------------\n",
            "ğŸ“Œ [Váº¬N Dá»¤NG] Viá»‡c phÃ¡t triá»ƒn giao thá»©c HTTPS cÃ³ Ã½ nghÄ©a gÃ¬ Ä‘á»‘i vá»›i cÃ¡c cÃ´ng cá»¥ tÃ¬m kiáº¿m xáº¿p háº¡ng uy tÃ­n cho trang web?\n",
            "   A. Giáº£m dung lÆ°á»£ng tá»‡p  |  B. TÄƒng tá»‘c Ä‘á»™ Internet  |  C. Chá»‰ báº£o vá»‡ mÃ¡y tÃ­nh  |  D. Báº£o vá»‡ cÃ¡c thÃ´ng tin nháº¡y cáº£m nhÆ° máº­t kháº©u, tÃ i khoáº£n ngÃ¢n hÃ ng hoáº·c dá»¯ liá»‡u cÃ¡ nhÃ¢n\n",
            "   âœ… ÄÃP ÃN: D. Báº£o vá»‡ cÃ¡c thÃ´ng tin nháº¡y cáº£m nhÆ° máº­t kháº©u, tÃ i khoáº£n ngÃ¢n hÃ ng hoáº·c dá»¯ liá»‡u cÃ¡ nhÃ¢n\n",
            "--------------------------------------------------\n",
            "ğŸ“Œ [NHáº¬N BIáº¾T] Truyá»‡n ngáº¯n 'Vá»£ nháº·t' lÃ  sÃ¡ng tÃ¡c cá»§a nhÃ  vÄƒn nÃ o?\n",
            "   A. Nguyá»…n Quang SÃ¡ng  |  B. Kim LÃ¢n  |  C. Nguyá»…n Minh ChÃ¢u  |  D. Nguyá»…n Du\n",
            "   âœ… ÄÃP ÃN: B. Kim LÃ¢n\n",
            "--------------------------------------------------\n",
            "ğŸ“Œ [THÃ”NG HIá»‚U] HÃ nh Ä‘á»™ng cá»§a TrÃ ng khi Ä‘Æ°a ngÆ°á»i Ä‘Ã n bÃ  xa láº¡ vá» lÃ m vá»£ thá»ƒ hiá»‡n Ä‘iá»u gÃ¬?\n",
            "   A. LÃ²ng nhÃ¢n háº­u vÃ  niá»m tin vÃ o tÆ°Æ¡ng lai.  |  B. Sá»± sá»£ hÃ£i trÆ°á»›c sá»± dá»¯ dáº±n cá»§a náº¡n Ä‘Ã³i.  |  C. Sá»± há»‘i háº­n vÃ¬ Ä‘Ã£ láº¥y vá»£ quÃ¡ vá»™i vÃ ng.  |  D. Sá»± má»‡t má»i vÃ¬ pháº£i chá» Ä‘á»£i ngÆ°á»i vá»£ Ä‘áº¿n.\n",
            "   âœ… ÄÃP ÃN: A. LÃ²ng nhÃ¢n háº­u vÃ  niá»m tin vÃ o tÆ°Æ¡ng lai.\n",
            "--------------------------------------------------\n",
            "ğŸ“Œ [Váº¬N Dá»¤NG] Viá»‡c nhÃ¢n váº­t TrÃ ng liá»u lÄ©nh Ä‘Æ°a ngÆ°á»i Ä‘Ã n bÃ  xa láº¡ vá» lÃ m vá»£ thá»ƒ hiá»‡n chÃ¢n lÃ½ nhÃ¢n Ä‘áº¡o nÃ o?\n",
            "   A. Con ngÆ°á»i chá»‰ cÃ³ thá»ƒ sá»‘ng sÃ³t khi cÃ³ tiá»n báº¡c.  |  B. TÃ¬nh ngÆ°á»i khÃ´ng ngá»«ng khÃ¡t khao háº¡nh phÃºc, váº«n Ä‘Ã¹m bá»c vÃ  yÃªu thÆ°Æ¡ng nhau Ä‘á»ƒ vÆ°á»£t qua nghá»‹ch cáº£nh.  |  C. Chá»‰ cÃ³ tÃ¬nh yÃªu Ä‘Ã´i lá»©a lÃ  Ä‘á»§ háº¡nh phÃºc.  |  D. NgÆ°á»i phá»¥ ná»¯ luÃ´n yáº¿u Ä‘uá»‘i trÆ°á»›c hoÃ n cáº£nh.\n",
            "   âœ… ÄÃP ÃN: B. TÃ¬nh ngÆ°á»i khÃ´ng ngá»«ng khÃ¡t khao háº¡nh phÃºc, váº«n Ä‘Ã¹m bá»c vÃ  yÃªu thÆ°Æ¡ng nhau Ä‘á»ƒ vÆ°á»£t qua nghá»‹ch cáº£nh.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Demo"
      ],
      "metadata": {
        "id": "nixCVVAf1n_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. CÃ€I Äáº¶T THÆ¯ VIá»†N\n",
        "!pip install -q gradio transformers torch pandas openpyxl\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "import re\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from difflib import SequenceMatcher\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from google.colab import drive\n",
        "\n",
        "# 2. LOAD MODEL\n",
        "if not os.path.exists('/content/drive'): drive.mount('/content/drive')\n",
        "MODEL_PATH = \"/content/drive/MyDrive/KhoaLuan/model_final/v2/model_vit5_final_ultra\"\n",
        "# ÄÆ°á»ng dáº«n file lÆ°u trá»¯ trÃªn Drive\n",
        "SAVE_PATH = \"/content/drive/MyDrive/KhoaLuan/generated_quizzes.xlsx\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"â³ Äang táº£i model tá»«: {MODEL_PATH} ...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH).to(DEVICE)\n",
        "print(\"âœ… Há»‡ thá»‘ng Ä‘Ã£ sáºµn sÃ ng!\")\n",
        "\n",
        "# 3. KHO ÄÃP ÃN NHIá»„U (Giá»¯ nguyÃªn tá»« code cá»§a báº¡n)\n",
        "BACKUP_OPTIONS = {\n",
        "    \"ToÃ¡n há»c\": [\"Sá»‘ há»¯u tá»‰\", \"HÃ m sá»‘ báº­c nháº¥t\", \"Äá»‹nh lÃ­ Pythagore\", \"Tam giÃ¡c Ä‘á»“ng dáº¡ng\", \"Há»‡ phÆ°Æ¡ng trÃ¬nh\", \"Äáº¡o hÃ m\", \"TÃ­ch phÃ¢n\"],\n",
        "    \"Váº­t lÃ½\": [\"Äá»‹nh luáº­t Newton\", \"Äiá»‡n trá»Ÿ\", \"Pháº£n xáº¡ Ã¡nh sÃ¡ng\", \"Dao Ä‘á»™ng cÆ¡\", \"SÃ³ng dá»«ng\", \"DÃ²ng Ä‘iá»‡n xoay chiá»u\"],\n",
        "    \"HÃ³a há»c\": [\"Báº£ng tuáº§n hoÃ n\", \"LiÃªn káº¿t cá»™ng hÃ³a trá»‹\", \"Pháº£n á»©ng tháº¿\", \"Kim loáº¡i kiá»m\", \"Ancol\", \"Polime\", \"Sáº¯t vÃ  há»£p cháº¥t\"],\n",
        "    \"Sinh há»c\": [\"Táº¿ bÃ o nhÃ¢n thá»±c\", \"Quang há»£p\", \"NguyÃªn phÃ¢n\", \"Di truyá»n há»c\", \"Há»‡ sinh thÃ¡i\", \"Chá»n lá»c tá»± nhiÃªn\"],\n",
        "    \"Lá»‹ch sá»­\": [\"Phong trÃ o Cáº§n vÆ°Æ¡ng\", \"CÃ¡ch máº¡ng thÃ¡ng TÃ¡m\", \"Chiáº¿n dá»‹ch Äiá»‡n BiÃªn Phá»§\", \"ToÃ n cáº§u hÃ³a\", \"Chiáº¿n tranh láº¡nh\"],\n",
        "    \"Äá»‹a lÃ½\": [\"Äá»‹a hÃ¬nh nhiá»‡t Ä‘á»›i\", \"GiÃ³ mÃ¹a\", \"Máº­t Ä‘á»™ dÃ¢n sá»‘\", \"Chuyá»ƒn dá»‹ch cÆ¡ cáº¥u kinh táº¿\", \"VÃ¹ng kinh táº¿ trá»ng Ä‘iá»ƒm\"],\n",
        "    \"Tin há»c\": [\"Há»‡ Ä‘iá»u hÃ nh\", \"Máº¡ng mÃ¡y tÃ­nh\", \"TrÃ¬nh duyá»‡t Web\", \"NgÃ´n ngá»¯ láº­p trÃ¬nh\", \"CÆ¡ sá»Ÿ dá»¯ liá»‡u\", \"TrÃ­ tuá»‡ nhÃ¢n táº¡o\"],\n",
        "    \"Ngá»¯ vÄƒn\": [\"Hiá»‡n thá»±c phÃª phÃ¡n\", \"VÄƒn há»c lÃ£ng máº¡n\", \"NhÃ¢n Ä‘áº¡o\", \"TÃ¬nh huá»‘ng truyá»‡n\", \"BÃºt phÃ¡p nghá»‡ thuáº­t\", \"Tá»‘ Há»¯u\", \"Nam Cao\"],\n",
        "    \"CÃ´ng nghá»‡\": [\"Báº£n váº½ ká»¹ thuáº­t\", \"Gia cÃ´ng cÆ¡ khÃ­\", \"Máº¡ch Ä‘iá»‡n Ä‘iá»u khiá»ƒn\", \"Äá»™ng cÆ¡ Ä‘á»‘t trong\", \"NÃ´ng nghiá»‡p cÃ´ng nghá»‡ cao\"],\n",
        "    \"GiÃ¡o dá»¥c Kinh táº¿ vÃ  PhÃ¡p luáº­t\": [\"Thá»‹ trÆ°á»ng\", \"Cung cáº§u\", \"Láº¡m phÃ¡t\", \"Thuáº¿\", \"Quyá»n dÃ¢n sá»±\", \"Hiáº¿n phÃ¡p\", \"PhÃ¡p luáº­t lao Ä‘á»™ng\"]\n",
        "}\n",
        "\n",
        "# --- CÃC HÃ€M Xá»¬ LÃ LOGIC ---\n",
        "def get_smart_options_safe(options_dict, context, subject):\n",
        "    seen_values = set()\n",
        "    final_opts = {}\n",
        "    backups = BACKUP_OPTIONS.get(subject, [\"PhÆ°Æ¡ng Ã¡n A\", \"PhÆ°Æ¡ng Ã¡n B\"]).copy()\n",
        "    random.shuffle(backups)\n",
        "    for key, value in options_dict.items():\n",
        "        clean_val = value.lower().replace(\".\", \"\").strip()\n",
        "        if clean_val not in seen_values and len(clean_val) > 2:\n",
        "            seen_values.add(clean_val)\n",
        "            final_opts[key] = value\n",
        "        else:\n",
        "            if backups:\n",
        "                new_val = backups.pop()\n",
        "                while new_val.lower() in seen_values and backups:\n",
        "                    new_val = backups.pop()\n",
        "                final_opts[key] = new_val\n",
        "                seen_values.add(new_val.lower())\n",
        "    return dict(sorted(final_opts.items()))\n",
        "\n",
        "def get_best_match(context, options_dict, model_ans_char):\n",
        "    best_key = model_ans_char\n",
        "    highest_score = 0\n",
        "    for key, content in options_dict.items():\n",
        "        match_ratio = SequenceMatcher(None, content, context).ratio()\n",
        "        if match_ratio > highest_score:\n",
        "            highest_score = match_ratio\n",
        "            best_key = key\n",
        "    return best_key if highest_score > 0.5 else model_ans_char\n",
        "\n",
        "def generate_quiz_gradio(subject, topic, level, context):\n",
        "    input_text = f\"mÃ´n: {subject} | chá»§ Ä‘á»: {topic} | má»©c Ä‘á»™: {level} | ngá»¯ cáº£nh: {context}\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs.input_ids, max_length=320, do_sample=True,\n",
        "            num_beams=3, temperature=0.7, repetition_penalty=1.5,\n",
        "            no_repeat_ngram_size=3, early_stopping=True\n",
        "        )\n",
        "    raw_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    pattern = r\"(?si)question\\s*[:\\-]\\s*(.*?)\\s*options\\s*[:\\-]\\s*(.*?)\\s*answer\\s*[:\\-]\\s*(.*)\"\n",
        "    match = re.search(pattern, raw_output)\n",
        "    if match:\n",
        "        q = match.group(1).strip()\n",
        "        opts_str = match.group(2).strip()\n",
        "        ans_raw = match.group(3).strip()\n",
        "        opts_list = re.findall(r\"([A-D])\\.\\s*(.*?)(?=\\s*[A-D]\\.|$)\", opts_str + \" \", re.DOTALL)\n",
        "        options_dict = {k: v.strip() for k, v in opts_list}\n",
        "        options_dict = get_smart_options_safe(options_dict, context, subject)\n",
        "        model_ans_char = ans_raw[0].upper() if len(ans_raw) > 0 else \"A\"\n",
        "        final_key = get_best_match(context, options_dict, model_ans_char)\n",
        "        full_opts = \"\\n\".join([f\"{k}. {v}\" for k, v in options_dict.items()])\n",
        "        correct_ans = f\"{final_key}. {options_dict.get(final_key)}\"\n",
        "        return q, full_opts, correct_ans\n",
        "    return \"âš ï¸ Lá»—i format output\", \"\", \"\"\n",
        "\n",
        "# --- HÃ€M LÆ¯U Dá»® LIá»†U ---\n",
        "def save_to_excel(subject, topic, level, context, question, options, answer):\n",
        "    if not question or \"âš ï¸\" in question:\n",
        "        return \"âŒ KhÃ´ng cÃ³ cÃ¢u há»i há»£p lá»‡ Ä‘á»ƒ lÆ°u!\"\n",
        "\n",
        "    new_data = {\n",
        "        \"Thá»i gian\": [datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")],\n",
        "        \"MÃ´n há»c\": [subject],\n",
        "        \"Chá»§ Ä‘á»\": [topic],\n",
        "        \"Má»©c Ä‘á»™\": [level],\n",
        "        \"Ngá»¯ cáº£nh\": [context],\n",
        "        \"CÃ¢u há»i\": [question],\n",
        "        \"Lá»±a chá»n\": [options.replace(\"\\n\", \" | \")],\n",
        "        \"ÄÃ¡p Ã¡n Ä‘Ãºng\": [answer]\n",
        "    }\n",
        "    df_new = pd.DataFrame(new_data)\n",
        "\n",
        "    try:\n",
        "        if os.path.exists(SAVE_PATH):\n",
        "            df_old = pd.read_excel(SAVE_PATH)\n",
        "            df_final = pd.concat([df_old, df_new], ignore_index=True)\n",
        "        else:\n",
        "            df_final = df_new\n",
        "\n",
        "        df_final.to_excel(SAVE_PATH, index=False)\n",
        "        return f\"âœ… ÄÃ£ lÆ°u vÃ o Drive: {SAVE_PATH}\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Lá»—i khi lÆ°u: {str(e)}\"\n",
        "\n",
        "\n",
        "# 5. GIAO DIá»†N GRADIO (CÃ‚N Báº°NG KÃCH THÆ¯á»šC CÃC Ã” Äáº¦U RA)\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# ğŸ“ Há»† THá»NG SINH CÃ‚U Há»I TRáº®C NGHIá»†M AI (ViT5)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            subject_in = gr.Dropdown(list(BACKUP_OPTIONS.keys()), label=\"ğŸ“š MÃ´n há»c\", value=\"Ngá»¯ vÄƒn\")\n",
        "            topic_in = gr.Textbox(label=\"ğŸ” Chá»§ Ä‘á»\", placeholder=\"VÃ­ dá»¥: Quy luáº­t cung cáº§u...\")\n",
        "            level_in = gr.Radio([\"Nháº­n biáº¿t\", \"ThÃ´ng hiá»ƒu\", \"Váº­n dá»¥ng\"], label=\"ğŸ§  Má»©c Ä‘á»™ tÆ° duy\", value=\"Nháº­n biáº¿t\")\n",
        "            context_in = gr.Textbox(label=\"ğŸ“ Ngá»¯ cáº£nh\", lines=5, placeholder=\"Nháº­p Ä‘oáº¡n vÄƒn báº£n Ä‘á»ƒ AI phÃ¢n tÃ­ch...\")\n",
        "            btn_gen = gr.Button(\"ğŸ”¥ SINH CÃ‚U Há»I\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            # Ã” CÃ¢u há»i: Tá»± Ä‘á»™ng co giÃ£n tá»‘i Ä‘a 10 dÃ²ng\n",
        "            res_q = gr.Textbox(\n",
        "                label=\"â“ CÃ¢u há»i sinh ra\",\n",
        "                lines=3,\n",
        "                max_lines=10,\n",
        "                interactive=False\n",
        "            )\n",
        "            # Ã” PhÆ°Æ¡ng Ã¡n: Tá»± Ä‘á»™ng co giÃ£n tá»‘i Ä‘a 15 dÃ²ng\n",
        "            res_opts = gr.Textbox(\n",
        "                label=\"ğŸ“‹ CÃ¡c phÆ°Æ¡ng Ã¡n\",\n",
        "                lines=5,\n",
        "                max_lines=15,\n",
        "                interactive=False\n",
        "            )\n",
        "            # Ã” ÄÃ¡p Ã¡n Ä‘Ãºng: ÄÃ£ chá»‰nh lines=3 vÃ  max_lines=10 Ä‘á»ƒ báº±ng vá»›i Ã´ CÃ¢u há»i\n",
        "            res_ans = gr.Textbox(\n",
        "                label=\"âœ… ÄÃ¡p Ã¡n Ä‘Ãºng\",\n",
        "                lines=3,           # Thiáº¿t láº­p máº·c Ä‘á»‹nh 3 dÃ²ng giá»‘ng res_q\n",
        "                max_lines=10,      # Tá»± Ä‘á»™ng giÃ£n ná»Ÿ tá»‘i Ä‘a 10 dÃ²ng nÆ°Æ¡ng theo ná»™i dung\n",
        "                interactive=False\n",
        "            )\n",
        "            btn_save = gr.Button(\"ğŸ’¾ LÆ¯U VÃ€O DRIVE\", variant=\"secondary\")\n",
        "            status_msg = gr.Markdown()\n",
        "\n",
        "    # Thiáº¿t láº­p cÃ¡c sá»± kiá»‡n Click (giá»¯ nguyÃªn logic xá»­ lÃ½)\n",
        "    btn_gen.click(\n",
        "        fn=generate_quiz_gradio,\n",
        "        inputs=[subject_in, topic_in, level_in, context_in],\n",
        "        outputs=[res_q, res_opts, res_ans]\n",
        "    )\n",
        "\n",
        "    btn_save.click(\n",
        "        fn=save_to_excel,\n",
        "        inputs=[subject_in, topic_in, level_in, context_in, res_q, res_opts, res_ans],\n",
        "        outputs=[status_msg]\n",
        "    )\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\"GiÃ¡o dá»¥c Kinh táº¿ vÃ  PhÃ¡p luáº­t\", \"Cung - Cáº§u\", \"ThÃ´ng hiá»ƒu\", \"Khi giÃ¡ cáº£ hÃ ng hÃ³a tÄƒng lÃªn, cÃ¡c doanh nghiá»‡p má»Ÿ rá»™ng sáº£n xuáº¥t lÃ m cung tÄƒng.\"],\n",
        "            [\"ToÃ¡n há»c\", \"HÃ m sá»‘\", \"Nháº­n biáº¿t\", \"HÃ m sá»‘ y = ax + b Ä‘á»“ng biáº¿n khi a > 0.\"],\n",
        "        ],\n",
        "        inputs=[subject_in, topic_in, level_in, context_in]\n",
        "    )\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "MU6bSNdd1p38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "1e8ec026-07f6-4e45-e30a-99bbb3a7adb1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â³ Äang táº£i model tá»«: /content/drive/MyDrive/KhoaLuan/model_final/v2/model_vit5_final_ultra ...\n",
            "âœ… Há»‡ thá»‘ng Ä‘Ã£ sáºµn sÃ ng!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2636561650.py:128: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft()) as demo:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://52b059033845ff2de1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://52b059033845ff2de1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://52b059033845ff2de1.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}